---
layout: post
title: "주요국의 인공지능과 데이터보호 정책 동향 분석 "
# subtitle: "first post"
date: 2021-07-07 22:00:0
background: '/img/posts/02.jpg'
---
## 주요국의 인공지능과 데이터보호 정책 동향 분석 - 영국과 싱가포르의 가이드를 중심으로

### I. 서론
인공지능 기술 도입에 따라 부상한 프라이버시 침해, 공정성, 투명성, 책임성 등의 각종 윤리적 이슈 등을 해결하기 위해 주요국 정부와 기업들이 나서고 있다. 윤리적 이슈는 말 그대로 법으로 규율하기 어려운 도덕과 윤리의 영역인 경우가 대부분이므로 각 국의 정부정책은 자율적인 이행을 촉진하며 우수사례 등을 제시하고 권고하는 원칙이나 지침, 가이드라인의 형식을 띠고 있다.

인공지능과 관련하여 데이터 및 개인정보 보호 관련 문제는 데이터가 개인정보에 해당 하는 경우 이를 개인정보보호 원칙에 맞게 최소한으로 정확한 정보를 수집해야 하며, 당초 수집한 목적으로만 이용해야 하고 일정 저장기간 후에는 파기하는 등 수집 단계에 해당하는 이슈들이 주로 거론된다. 인공지능에 활용하는 대량의 데이터 보안과 안전성 확보를 통한 데이터 유ᆞ노출 리스크 대응과 유럽연합 일반 개인정보보호법(GDPR) 등 법적으로도 보장하는 정보주체의 권리와 관련해서도 활발한 논의가 지속되고 있다.

### II. 주요국 정책 동향

**< 인공지능 정의 >**

- “복잡 한 목표가 주어졌을 때 데이터 획득을 통해 환경을 인식하고 수집한 정형 또는 비정형 데이터를 해석ᆞ추론함으로써 최선의 조치를 결정하고 물리적 차원이나 디지털 차원에서 행동하도록 인간이 설계한 소프트웨어(하드웨어도 가능) 시스템 - 유럽연합 집행위원회의 고위 전문가 그룹

- “인식, 음성인식 및 언어 번역과 같이 인간의 지능이 필요한 작업을 수행할 수 있는 기술” - 영국 상원의 인공지능 특별위원회


- 일본 관민데이터활용추진기본법

    “인공적인 방법으로 학 습, 추론, 판단 등의 지적인 기능을 실현하고 인공적인 방법으로 실현된 당해 기능의 활용에 관한 기술”

→ 조금씩 상이하지만 주로 인간지능과 연결된 인지 문제 해결을 위한 결정을 내리는 데에 기여하는 기술을 인공지능이라고 인식하는 공통점..

인공지능 윤리 이슈는 프라이버시, 책임성, 안전 및 보안, 투명성 및 설명 가능성, 공정 성 및 비차별, 인간의 기술 통제, 전문가 책임, 인간 가치 증진 등을 주요 주제로 꼽음.

![https://s3-us-west-2.amazonaws.com/secure.notion-static.com/c48e55a6-08dd-408f-b05c-255abcb16871/Untitled.png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/c48e55a6-08dd-408f-b05c-255abcb16871/Untitled.png)

### III. 싱가포르의 “AI 거버넌스 프레임워크 모델 도입 가이드”

1. 운용 관리

    ![https://s3-us-west-2.amazonaws.com/secure.notion-static.com/772c080a-3019-442b-9473-8dc21f340a53/Untitled.png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/772c080a-3019-442b-9473-8dc21f340a53/Untitled.png)
  
2. 이해관계자와의 소통 및 상호작용

### IV. 영국의 “인공지능 및 데이터보호 가이드”

1. 책임성과 거버넌스 (accountability and governace)

    GDPR 제35조에 따르면 개인정보 영향평가는 자동화된 처리에 근거한 개인에 관한 개인적 측면을 체계적이고 광범위하게 평가하는 것으로, 해당 평가에 근거한 결정이 1 해당 개인에게 법적 효력을 미치거나 이와 유사하게 개인에게 중대한 영향을 미치는 경우, 2 특정 범주의 개인정보에 대한 대규모 처리나 범죄 경력 및 범죄 행위에 관련된 개인정보에 대한 처리, 3 공개적으로 접근 가능한 지역에 대한 대규모 모니터링 등의 경우 수행하도록 하고 있다. 영향평가 대상 외에 자동화된 처리 관련하여 개인정보 영향평가 방안의 특화된 사항은 GDPR에 규정하고 있지 않다.

    ![https://s3-us-west-2.amazonaws.com/secure.notion-static.com/3b17fbed-07c3-4bef-935f-34bf22314088/Untitled.png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/3b17fbed-07c3-4bef-935f-34bf22314088/Untitled.png)

2. 공정하고 합법적이며 투명한 처리

    공정성의 구현과 차별성 완화를 위해서는 모든 단계에 걸쳐 편향을 완화하는 접근방식을 문서화하 고 정책과 모범사례를 마련함과 동시에 모니터링을 지속 수행하고 조직 내에서 편견과 차별을 식별할 수 있도록 다양한 인력으로 조직을 운영해야 한다고 규정하고 있다.

    또한, 합법성을 위해서도 법적 근거를 선택하여 모든 결정 내용을 문서화하고 정당한 사유 없이 추후 법적 근거를 변경하지 못하도록 필수 고려사항을 제시하며, 데이터 수집을 위한 동의도 쉽게 동의철회가 가능해야 하므로 수용할 준비를 하도록 하는 내용을 포함한다

    ![https://s3-us-west-2.amazonaws.com/secure.notion-static.com/e7f39776-6bba-4d36-a014-0be02a2849cd/Untitled.png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/e7f39776-6bba-4d36-a014-0be02a2849cd/Untitled.png)

3. 데이터 최소화와 보안

    [표 6]처럼 보안 강화를 위해서는 학습 데이터와 인공지능 모델의 위험을 관리하도록 하고 있으며, 데이터 최소화 방안으로는 학습 단계와 추론 단계, 모델 수립 후를 나누어서 설명한다. 학습 단계는 노이즈 추가, 데이터 합성, 연합 학습 등의 기법을 활용하도록 하고, 추론 단계는 인간 판독이 어려운 형식으로 데이터를 변환하는 등 개인정 보 활용을 최소화하는 방안을 제시하며, 모델 수립 후에는 재학습 가능성이 낮고 일정기간 이 경과한 데이터는 모두 파기하도록 하는 방안을 제시한다. 결국, 개인정보가 활용되는 모든 프로세스에 대해 데이터 최소화 방안을 매핑하고 실행하도록 권장하는 것으로 판단 된다.

    ![https://s3-us-west-2.amazonaws.com/secure.notion-static.com/e67d44b2-23ea-46a3-a3ec-dba4f5cbd50e/Untitled.png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/e67d44b2-23ea-46a3-a3ec-dba4f5cbd50e/Untitled.png)

4. 정보주체의 권리보장
\
    전반적으로 인공지능 시스템에서도 정 정권, 삭제권, 데이터 이동권, 정보를 제공받을 권리가 모두 적용된다고 보고 있으나 데이 터 이동권과 정보를 제공받을 권리는 일정 조건을 두고 있다. 데이터 이동권은 개인정보 처리가 동의나 계약에 근거한 경우만 적용이 가능하며, 정보를 제공받을 권리는 의사결정에 대한 개인정보를 처리하는 경우에만 적용될 수 있다는 점을 주의해야 한다.
    인공지능 모델에서 특정 개인의 정정권이나 삭제권 요구가 있을 시에 이를 반영해줄
    수 있는지, 어느 선까지 반영할 수 있는지 이견이 분분[5]했지만 본 지침에선 정정권ᆞ삭
    제권 모두 보장해주어야 한다고 보며, 특히 삭제권은 한 개인의 정보를 삭제하는 것이
    목적 달성에 영향이 있지 않으므로 요청을 이행하지 않을 근거가 되지 않는다고 서술하고
    있다. 다만, 모든 머신러닝 모델을 삭제할 근거는 되지 않고 해당 개인의 데이터만 삭제할
    것을 권고하고 있다. 또한, 자동화된 결정 관련 권리 보장 방안으로 필요한 경우 인공지능
    시스템의 결정을 무효화해야 한다고도 밝히고 있어 강력하게 개인의 권리 보장을 권고하

    고 있음을 알 수 있다.

    ![https://s3-us-west-2.amazonaws.com/secure.notion-static.com/9eb40006-7405-4f24-a5cb-f36b26fcea75/Untitled.png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/9eb40006-7405-4f24-a5cb-f36b26fcea75/Untitled.png)

### V. 시사점

1. 인공지능 시스템을 운영하는 조직의 책임성과 투명성을 구현하기 위해서는 문서화가 필수적이며, 학습 데이터의 관리의 병행이 중요하다. 

    싱가포르의 가이드는 인공지능 모델의 작동 방식을 기록하고 산출 결과와 과정 또한 모두 기록하도록 하고, 심지어는 기록용 블랙박스의 운영과 학습  이터 사본 관리로 데이터의 계보가 추적 가능해야 한다고 권장하고 있다. 영국의 가이드 또한 인공지능의 결정을 모두 문서화하도록 하며, 개인정보 영향평가의 경우 문서화할 사항을 별도로 제시하며 강조하기도 한다.

2. 인공지능 서비스의 정보주체 권리 보장과 이해관계자 간 소통 등의 중요성이 더욱 부상할 것이므로 이에 대한 준비가 요구될 것이다. 인공지능 서비스가 개인정보를 활용하여 의사결정을 내리는 경우 가령 면접이나 신용도 결정 등 민감한 사항에 대해서는 정보를 제공받을 권리나 정정권, 삭제권 등의 요구가 실제로 제기될 수 있다. 영국의 가이드에서 제시하고 있는 것처럼 이는 인공지능 시스템에서도 적용되어야 하고 보장해야 하는 권리로서 내부적인 기준과 절차를 마련하여야 할 것이다. 또한, 인공지능 프로세스 관련 이의 제기가 있는 경우 이를 검토할 수 있는 별도의 채널을 운영하고 실질적인 권리구제가 가능하도록 조치하여야 할 것이다.


3. 인공지능 프로세스의 데이터와 개인정보보호는 결국 시스템을 운영하는 기관이나 기업의 자율적인 실천으로 구현되는 것이기 때문에 관련법과 지침을 준수하고 우수사례를 공유하며 교육을 통해 인식을 제고하는 등의 지속적인 노력이 필수적이다. 본문에서 분석하고 있는 가이드 모두 강제성이 없는 자율적 실천을 가이드하는 권고안의 성격이며, 결국 이를 구현하기 위해서는 최고 경영자와 고위 임원들의 관심과 노력이 중요할 수밖에 없다. 인공지능 기술의 성능만을 중요시 하는 기업 방침 하에서는 가이드의 내용 모두 기술 개발의 걸림돌로 여겨질 뿐이다. 대량의 데이터를 필요로 하는 인공지능의 특성 상 시간과 인력을 투입하고 피드백을 받아 수정하고 지속적인 모니터링을 하는 데에는 자원의 배분이 불가피하다. 글로벌 기업의 경우는 사회적 책임 준수를 중요시하지만 규모 가 작은 스타트업 등의 경우 경영자들도 데이터 보호의 중요성을 인식하지 못할 수 있다. 최고 경영자와 고위 임원들의 인식을 제고하고 개인정보보호의 권고와 이를 유도할 수 있는 인센티브를 제공하는 등의 방안을 강구하는 것이 정책 당국의 중요한 과제가 될 것이 다.

참고 사이트 : [ITFIND](https://www.itfind.or.kr/publication/regular/weeklytrend/weekly/list.do)

[주요국의 인공지능과 데이터보호 정책 동향 분석.pdf](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/641b1fcc-c988-48ee-aa0f-be01783478a8/_____.pdf)